{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "-OMKuF25zTUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ndCdY3RPzGc_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variabels"
      ],
      "metadata": {
        "id": "hJi4wggu0z8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "img_size = 28\n",
        "patch_size = 7\n",
        "num_channels = 1\n",
        "num_patches = (img_size // patch_size) ** 2\n",
        "attention_heads = 4\n",
        "embed_dim = 16\n",
        "transformer_blocks = 4\n",
        "mlp_nodes = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "5ENsR0iDzWBx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Transform"
      ],
      "metadata": {
        "id": "G0Veq39504QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "2kDNcJTA018O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading MNIST dataset"
      ],
      "metadata": {
        "id": "HY8b1JJx6M02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "val_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                        download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKISHOxZ06pF",
        "outputId": "ab10bac8-69a3-4f11-c7ed-97836329ae25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 495kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.66MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Train and Validation batches"
      ],
      "metadata": {
        "id": "FAjW6ZOi6YIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataloader.DataLoader(train_dataset, shuffle = True, batch_size =batch_size)\n",
        "val_data = dataloader.DataLoader(val_dataset, shuffle = True, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "bFubgZFR6Pt8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class for PatchEmbedding"
      ],
      "metadata": {
        "id": "6MO2LjHH83hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.patch_embed = nn.Conv2d(num_channels, embed_dim, kernel_size= patch_size, stride= patch_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.patch_embed(x)\n",
        "    x = x.flatten(2)\n",
        "    x = x.transpose(1,2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "0D3la1Nh7vbv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking dimensions"
      ],
      "metadata": {
        "id": "JWkHHhTh_d4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_data))\n",
        "print(\"Dimension of input train batch:\", images.shape)\n",
        "patch_embed = nn.Conv2d(num_channels, 20, kernel_size= patch_size, stride= patch_size)\n",
        "embedded_image = patch_embed(images)\n",
        "print(\"Dimension of input train batch after conv2d:\", embedded_image.shape)\n",
        "flattened_image = embedded_image.flatten(2)\n",
        "print(\"Dimension of input train batch after conv2d and flattening:\", flattened_image.shape)\n",
        "transposed_flattened_image = flattened_image.transpose(1,2)\n",
        "print(\"Dimension of input train batch after conv2d and flattening and transposed:\", transposed_flattened_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3T6H_58-6AA",
        "outputId": "515b950b-c88d-4ec5-8f31-4c294a17d0d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of input train batch: torch.Size([64, 1, 28, 28])\n",
            "Dimension of input train batch after conv2d: torch.Size([64, 20, 4, 4])\n",
            "Dimension of input train batch after conv2d and flattening: torch.Size([64, 20, 16])\n",
            "Dimension of input train batch after conv2d and flattening and transposed: torch.Size([64, 16, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class for Transformer Encoder"
      ],
      "metadata": {
        "id": "lVl55mCuCBHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "    self.multi_head_attention = nn.MultiheadAttention(embed_dim, attention_heads, batch_first = True)\n",
        "    self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(embed_dim, mlp_nodes),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(mlp_nodes, embed_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual1 = x\n",
        "    x = self.layer_norm1(x)\n",
        "    x = self.multi_head_attention(x, x, x)[0]\n",
        "    x = x + residual1\n",
        "    residual2 = x\n",
        "    x = self.layer_norm2(x)\n",
        "    x = self.mlp(x)\n",
        "    x = x + residual2\n",
        "    return x"
      ],
      "metadata": {
        "id": "FgSCQuNz_TXs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class for MLP Head"
      ],
      "metadata": {
        "id": "GPYrCiN0Gcj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_Head(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "    self.mlp_head = nn.Sequential(\n",
        "        #nn.Linear(embed_dim),\n",
        "        nn.Linear(embed_dim, num_classes)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    #x = x[:,0]\n",
        "    x = self.layer_norm1(x)\n",
        "    x = self.mlp_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "IaqLtk38GRJf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class VisionTransformer"
      ],
      "metadata": {
        "id": "yuugzB94I6Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.patch_embedding = PatchEmbedding()\n",
        "    self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "    self.position_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))\n",
        "    self.transformer_blocks = nn.Sequential(*[TransformerEncoder() for _ in range(transformer_blocks)])\n",
        "    self.mlp_head = MLP_Head()\n",
        "  def forward(self, x):\n",
        "    x = self.patch_embedding(x)\n",
        "    B = x.shape[0]\n",
        "    cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "    x = torch.cat((cls_tokens, x), 1)\n",
        "    x = x + self.position_embedding\n",
        "    x = self.transformer_blocks(x)\n",
        "    x = x[:,0]\n",
        "    x = self.mlp_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NgeFTW0HINjO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting device"
      ],
      "metadata": {
        "id": "iFaPSIFvOp_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "qzXT-LY9OkP0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Model"
      ],
      "metadata": {
        "id": "-IOwxi7WPmWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionTransformer().to(device)"
      ],
      "metadata": {
        "id": "NK73dDEqPrAg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer"
      ],
      "metadata": {
        "id": "y010P-LFO5E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "Ve0KUUWLO3r1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "iVxmeEhtSEBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "7SBgbW-3SFrG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "mScrUuXfRdJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_epoch = 0\n",
        "    total_epoch = 0\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_data):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss+=loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        correct = (preds == labels).sum().item()\n",
        "        accuracy = 100.0 * correct / labels.size(0)\n",
        "\n",
        "        correct_epoch += correct\n",
        "        total_epoch += labels.size(0)\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"  Batch {batch_idx+1:3d}: Loss = {loss.item():.4f}, Accuracy = {accuracy:.2f}%\")\n",
        "\n",
        "    epoch_acc = 100.0 * correct_epoch / total_epoch\n",
        "    print(f\"==> Epoch {epoch+1} Summary: Total Loss = {total_loss:.4f}, Accuracy = {epoch_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXNYUUojPR9B",
        "outputId": "61783cbe-15a0-49d8-bf86-e6ddae3752dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "  Batch   1: Loss = 2.4827, Accuracy = 6.25%\n",
            "  Batch 101: Loss = 1.6192, Accuracy = 50.00%\n",
            "  Batch 201: Loss = 0.7386, Accuracy = 82.81%\n",
            "  Batch 301: Loss = 0.5873, Accuracy = 81.25%\n",
            "  Batch 401: Loss = 0.3585, Accuracy = 90.62%\n",
            "  Batch 501: Loss = 0.4965, Accuracy = 85.94%\n",
            "  Batch 601: Loss = 0.1839, Accuracy = 95.31%\n",
            "  Batch 701: Loss = 0.1165, Accuracy = 96.88%\n",
            "  Batch 801: Loss = 0.4038, Accuracy = 87.50%\n",
            "  Batch 901: Loss = 0.2681, Accuracy = 93.75%\n",
            "==> Epoch 1 Summary: Total Loss = 581.2294, Accuracy = 81.23%\n",
            "\n",
            "Epoch 2\n",
            "  Batch   1: Loss = 0.2691, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.2304, Accuracy = 96.88%\n",
            "  Batch 201: Loss = 0.0623, Accuracy = 98.44%\n",
            "  Batch 301: Loss = 0.2131, Accuracy = 96.88%\n",
            "  Batch 401: Loss = 0.2257, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1221, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.3511, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.1896, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.1742, Accuracy = 95.31%\n",
            "  Batch 901: Loss = 0.0663, Accuracy = 96.88%\n",
            "==> Epoch 2 Summary: Total Loss = 185.1692, Accuracy = 94.08%\n",
            "\n",
            "Epoch 3\n",
            "  Batch   1: Loss = 0.2143, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.2557, Accuracy = 90.62%\n",
            "  Batch 201: Loss = 0.0522, Accuracy = 100.00%\n",
            "  Batch 301: Loss = 0.3862, Accuracy = 90.62%\n",
            "  Batch 401: Loss = 0.0776, Accuracy = 96.88%\n",
            "  Batch 501: Loss = 0.0886, Accuracy = 98.44%\n",
            "  Batch 601: Loss = 0.1958, Accuracy = 93.75%\n",
            "  Batch 701: Loss = 0.0514, Accuracy = 98.44%\n",
            "  Batch 801: Loss = 0.2096, Accuracy = 93.75%\n",
            "  Batch 901: Loss = 0.1915, Accuracy = 95.31%\n",
            "==> Epoch 3 Summary: Total Loss = 142.8242, Accuracy = 95.53%\n",
            "\n",
            "Epoch 4\n",
            "  Batch   1: Loss = 0.1059, Accuracy = 98.44%\n",
            "  Batch 101: Loss = 0.1000, Accuracy = 96.88%\n",
            "  Batch 201: Loss = 0.0756, Accuracy = 96.88%\n",
            "  Batch 301: Loss = 0.1970, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.2587, Accuracy = 93.75%\n",
            "  Batch 501: Loss = 0.0742, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.1258, Accuracy = 96.88%\n",
            "  Batch 701: Loss = 0.1322, Accuracy = 93.75%\n",
            "  Batch 801: Loss = 0.0906, Accuracy = 96.88%\n",
            "  Batch 901: Loss = 0.1278, Accuracy = 95.31%\n",
            "==> Epoch 4 Summary: Total Loss = 122.2769, Accuracy = 96.06%\n",
            "\n",
            "Epoch 5\n",
            "  Batch   1: Loss = 0.1611, Accuracy = 95.31%\n",
            "  Batch 101: Loss = 0.2580, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.0922, Accuracy = 96.88%\n",
            "  Batch 301: Loss = 0.1912, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.1443, Accuracy = 95.31%\n",
            "  Batch 501: Loss = 0.0916, Accuracy = 93.75%\n",
            "  Batch 601: Loss = 0.0701, Accuracy = 96.88%\n",
            "  Batch 701: Loss = 0.0847, Accuracy = 96.88%\n",
            "  Batch 801: Loss = 0.1162, Accuracy = 93.75%\n",
            "  Batch 901: Loss = 0.0821, Accuracy = 98.44%\n",
            "==> Epoch 5 Summary: Total Loss = 107.0726, Accuracy = 96.52%\n",
            "\n",
            "Epoch 6\n",
            "  Batch   1: Loss = 0.3398, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.0601, Accuracy = 98.44%\n",
            "  Batch 201: Loss = 0.1076, Accuracy = 96.88%\n",
            "  Batch 301: Loss = 0.2191, Accuracy = 92.19%\n",
            "  Batch 401: Loss = 0.0686, Accuracy = 98.44%\n",
            "  Batch 501: Loss = 0.1056, Accuracy = 96.88%\n",
            "  Batch 601: Loss = 0.0725, Accuracy = 98.44%\n",
            "  Batch 701: Loss = 0.0961, Accuracy = 96.88%\n",
            "  Batch 801: Loss = 0.1502, Accuracy = 96.88%\n",
            "  Batch 901: Loss = 0.1846, Accuracy = 95.31%\n",
            "==> Epoch 6 Summary: Total Loss = 96.4727, Accuracy = 96.80%\n",
            "\n",
            "Epoch 7\n",
            "  Batch   1: Loss = 0.0665, Accuracy = 98.44%\n",
            "  Batch 101: Loss = 0.1784, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.1064, Accuracy = 95.31%\n",
            "  Batch 301: Loss = 0.0245, Accuracy = 100.00%\n",
            "  Batch 401: Loss = 0.0570, Accuracy = 98.44%\n",
            "  Batch 501: Loss = 0.1087, Accuracy = 93.75%\n",
            "  Batch 601: Loss = 0.0644, Accuracy = 98.44%\n",
            "  Batch 701: Loss = 0.0120, Accuracy = 100.00%\n",
            "  Batch 801: Loss = 0.0209, Accuracy = 100.00%\n",
            "  Batch 901: Loss = 0.0622, Accuracy = 98.44%\n",
            "==> Epoch 7 Summary: Total Loss = 86.4021, Accuracy = 97.10%\n",
            "\n",
            "Epoch 8\n",
            "  Batch   1: Loss = 0.1145, Accuracy = 96.88%\n",
            "  Batch 101: Loss = 0.1475, Accuracy = 95.31%\n",
            "  Batch 201: Loss = 0.0378, Accuracy = 98.44%\n",
            "  Batch 301: Loss = 0.0523, Accuracy = 96.88%\n",
            "  Batch 401: Loss = 0.0872, Accuracy = 95.31%\n",
            "  Batch 501: Loss = 0.0459, Accuracy = 98.44%\n",
            "  Batch 601: Loss = 0.0118, Accuracy = 100.00%\n",
            "  Batch 701: Loss = 0.0422, Accuracy = 98.44%\n",
            "  Batch 801: Loss = 0.0205, Accuracy = 98.44%\n",
            "  Batch 901: Loss = 0.0633, Accuracy = 96.88%\n",
            "==> Epoch 8 Summary: Total Loss = 80.0015, Accuracy = 97.31%\n",
            "\n",
            "Epoch 9\n",
            "  Batch   1: Loss = 0.0138, Accuracy = 100.00%\n",
            "  Batch 101: Loss = 0.1019, Accuracy = 98.44%\n",
            "  Batch 201: Loss = 0.0592, Accuracy = 98.44%\n",
            "  Batch 301: Loss = 0.0487, Accuracy = 100.00%\n",
            "  Batch 401: Loss = 0.0402, Accuracy = 98.44%\n",
            "  Batch 501: Loss = 0.0276, Accuracy = 100.00%\n",
            "  Batch 601: Loss = 0.1317, Accuracy = 95.31%\n",
            "  Batch 701: Loss = 0.1797, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.0100, Accuracy = 100.00%\n",
            "  Batch 901: Loss = 0.1523, Accuracy = 95.31%\n",
            "==> Epoch 9 Summary: Total Loss = 76.7210, Accuracy = 97.45%\n",
            "\n",
            "Epoch 10\n",
            "  Batch   1: Loss = 0.0266, Accuracy = 100.00%\n",
            "  Batch 101: Loss = 0.0337, Accuracy = 100.00%\n",
            "  Batch 201: Loss = 0.1242, Accuracy = 95.31%\n",
            "  Batch 301: Loss = 0.0583, Accuracy = 98.44%\n",
            "  Batch 401: Loss = 0.0120, Accuracy = 100.00%\n",
            "  Batch 501: Loss = 0.0384, Accuracy = 98.44%\n",
            "  Batch 601: Loss = 0.1153, Accuracy = 95.31%\n",
            "  Batch 701: Loss = 0.1550, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.0161, Accuracy = 100.00%\n",
            "  Batch 901: Loss = 0.1186, Accuracy = 95.31%\n",
            "==> Epoch 10 Summary: Total Loss = 68.5505, Accuracy = 97.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation Accuracy"
      ],
      "metadata": {
        "id": "sTKfThyrVFyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_data:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = 100.0 * correct / total\n",
        "print(f\"\\n==> Val Accuracy: {test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEGQs7U_UE5X",
        "outputId": "1a18fb29-3690-4a5f-c91f-e20cc3f982d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==> Val Accuracy: 97.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6T8IQAq1Vjtv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}